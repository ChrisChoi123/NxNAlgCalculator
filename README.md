# NxNAlgCalulator
This program calculates the amount of algs (3-style comms) in the average NxN blind solve. It shows both my (Chris Choi) formula and Tom Nelson's formula from 2017. 

Thanks Graham Siggins for much of the information. This calculation was done assuming fixed buffer 3-style. For the corners and midges, I accounted for floating 2-twist and 2-flip. With these assumptions, Stanley Chapel arrived at 10.3 for the average alg count of a 3x3 solve. I also assumed the implemetation of the advanced "avoiding cycle breaks" during centres. For odd NxNs, the calculation was rather straightforward, but for even NxNs, I had to take account to the fact that you can orient it in an advantageous way due to lack of centre pieces. I did this using a modified inverse tangent function, which has the desired properties of an asymptote at infinity and a steep initial ascent.
I use 2 formulas, one for even and one for odd, where n is the number of layers.  

Odd: ((n-3)/2)*12+((n-3)/2)((n-3)/2+1)*9.7+4.12+6.18

Even: ((n-2)/2)*12+(((n-2)/2)^2)*(19.75n - 51.5727)/(2(n - 2.2324)) + 4.12

Work: 

8/13/2020:
I came up with the 4.12/6.18 split by analysing how Tom Nelson split up his corners and edges for the 3x3 part of the solve (corners and midges) and I used the same ratio (2:3). 

To derive the exact arctan expression, I used two very important pieces of information from Siggins, mainly that for 4x4 centers, it's 16 targets on average, for 6x6 it's 18 targets on average, and it approaches 19.5 targets as N approaches infinity, keeping in mind that algs is just targets/2 because 3-style. This was very convenient because the arctan function had the exact property I wanted; going from 16 to 18 in just an increment of 2 was pretty large, and we had a finite limit as n approaches infinity. So since 4x4 was essentially our starting point, as any even number input below that would be meaningless, I wanted the inflection point of the inverse tan graph to be n = 4. This means that the x variable in arctan(x) would be replaced with n - 4. Additionally, since the desireable values were from 16 to 19.5, this meant that the range was 3.5 The positive half of the arctan function has a range of pi/2, so I would have to multiply the arctan function by (2/pi)*(3.5) for the correct vertical dilation. However, we still need to add 16 because the inflection point of the parent arctan graph is at y = 0, and we want the target count to be 16 at the beginning when n = 4. Ok, that takes care of most of it, but we still need to use the 2nd point of data, that when n = 6 the target count is 18. This would be easy to do with a simple equation: 18 = 16 + (2*3.5/pi)arctan(cn - 4), where c is an unknown constant we have to mulitply n by to get the desired function. We want the equation to hold true when n is equal to 6, so we can solve for cn to find c. We get that cn is approximately 5.25396. Plugging in 6 for n, we get c = .87566. And finally, don't forget to divide by 2 in the final formula! 

8/14/20:
While browsing facebook, it came to my attention that someone had already calculated the average number of targets for centres in 4x4-14x4 and 20x20. This is a much larger sample size than what I previously used for the varying function, which was just 4x4,6x6, and an asymptote of 19.5. Additionally, I found that my arctan formula didn't even work properly in the first place, it was supposed to be 16 when n = 4, but it wasnt 16 because I forgot to distribute a constant out of both n and the -4 in the arctan's input. So I made the according change and I also shifted the arctan function up by 1 since Levi (the guy who ran the simulations that calculated the average center targets) had the 4x4 estimate target count as 16.1 and 6x6 as 18.1 (so I assumed an asymptote of 19.6). I compared my even layered results with Levi's estimates and I found that mine differed from his significantly for 10x10 to 14x14. I wasn't satisfied so I tried using another function I knew that had a similar behaviour to arctan: expotential. If you start with a parent function of y = -e^(-x), and going through the same process as what I did yesterday, I got y = -3.5e^(-.42365(x-4)+19.6. While the 4x4 and 6x6 results were exactly the same as Levi's estimate, after all I derived it based on those two data points, the rest of the NxN data points were very different. It was then that I had an epiphany to try using a rational function. There are an infinite set of parent rational functions, since it is just any polynomial divded by another, so I searched up a rational regression calculator and came upon https://goodcalculators.com/rational-function-regression-calculator/. This allowed me to simply input all of the date points from Levi's calculation and it gave me the equation  (19.9933x - 51.5727)/(x - 2.2324). 

Before I set out to test this equation's effectiveness in my formula, I merged my master branch with Stephen Huan's vresion of the file. He used a formula generator and used some fancy lambda stuff that I never learned, so thanks to him for that. It made my code a lot neater. So after this, I was able to replace the arctan function I was using and played around with the new rational function. To make the calculations match as closely as possible to Graham's estimates, I ended up changed the coefficient in the numerator 19.9933 to 19.75. This allowed all of my even estimates to be within .37, much more accurate than before. Additionally, I also improved my odd formula by changing the centre constant to 9.7, since it was previously 9.75 and I found that all of the odd calculations were overestimates from Graham's estimations. Overall, this improved the accuracy of my formulas by a factor of 2.15 geometrically and 1.46 arithmetically. 
